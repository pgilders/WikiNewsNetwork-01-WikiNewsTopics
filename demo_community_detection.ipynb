{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0f54e5",
   "metadata": {},
   "source": [
    "# How to identify groups of articles relevant to a specific news event\n",
    "\n",
    "Here we provide a demo of the temporal community detection procedure applied to an example event. The approach collects the groups of articles that are both well connected and exhibit similar patterns of page views to some specified seed articles.\n",
    "\n",
    "Note that data collection is not performed from scratch in this demo version, but the doc will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62542e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import WikiNewsNetwork as wnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089e5e9",
   "metadata": {},
   "source": [
    "## 1. Data collection\n",
    "\n",
    "N.B. This section incomplete at present and does not collect data from scratch.\n",
    "\n",
    "Take a sample event with hyperlinked Wikipedia articles and an event date. e.g.:\n",
    "\n",
    "_2018/11/30 ___[2018 Anchorage earthquake](https://en.wikipedia.org/wiki/2018_Anchorage_earthquake)___: A ___[magnitude](https://en.wikipedia.org/wiki/Moment_magnitude_scale)___ 7.0 earthquake hits Alaska, with the epicenter in ___[Anchorage](https://en.wikipedia.org/wiki/Anchorage,_Alaska)___. Severe damage is reported._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ['2018_Anchorage_earthquake', 'Moment_magnitude_scale', 'Anchorage,_Alaska']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7981f",
   "metadata": {},
   "source": [
    "Collect clickstream network data for period (download first if necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-collected data, will be updated to collect from scratch\n",
    "el = pd.read_hdf('demo/edgelist.h5')\n",
    "display(el.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a620f",
   "metadata": {},
   "source": [
    "Collect page view data for relevant articles in period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-collected data, will be updated to collect from scratch\n",
    "ts = pd.read_hdf('demo/timeseries.h5')\n",
    "display(ts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bceb70",
   "metadata": {},
   "source": [
    "Collect relevant redirects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da347a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not relevant here, encouraged if collecting own data through clickstream/dumps/API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a403f31",
   "metadata": {},
   "source": [
    "## 2. Processing\n",
    "\n",
    "Pre-process network and pageview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd00f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale page view data\n",
    "scaler = RobustScaler()\n",
    "timeseries = scaler.fit_transform(ts)\n",
    "\n",
    "# Filter edgelist \n",
    "el = el[el['n']>100]\n",
    "el = el[(el['prev'].isin(ts.columns)) & (el['curr'].isin(ts.columns))]\n",
    "\n",
    "# Convert to unweighted, undirected adjacency matrix\n",
    "articles = sorted(set(el['prev']) | set(el['curr']))\n",
    "network = (~el.pivot(index='prev', columns='curr', values='n').isna()\n",
    "               ).reindex(columns=articles, index=articles, fill_value=False)\n",
    "network = (network | network.T).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c581c9",
   "metadata": {},
   "source": [
    "Save network and page view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873498e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('demo/scaled_timeseries.npy', timeseries)\n",
    "network.to_hdf('demo/adj.h5', key='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362a933",
   "metadata": {},
   "source": [
    "## 3. Community detection\n",
    "\n",
    "Supply network and page view data to temporal community detection algorithm. The algorithm identifies groups of articles that are both well connected and exhibit similar attention dynamics around the time of the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c913233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data if necessary\n",
    "# timeseries = np.load('demo/scaled_timeseries.npy')\n",
    "# network = pd.read_hdf('demo/adj.h5')\n",
    "\n",
    "cd_output, nodename_dict = wnn.cd.cd_demo(timeseries, network, res=0.25, tau=1)\n",
    "# see docs for many more arguments to this function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ebbddc",
   "metadata": {},
   "source": [
    "Process community detection output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ac111",
   "metadata": {},
   "outputs": [],
   "source": [
    "membership_df = pd.concat([pd.Series(x, index=nodename_dict[n])\n",
    "                            for n, x in enumerate(cd_output[0])],\n",
    "                           axis=1, sort=True)\n",
    "display(membership_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a8ee6",
   "metadata": {},
   "source": [
    "Extract 'Event Reactions' - communities overlapping with event date (column 27) containing at least one of the previously specified core articles. We have identified the groups of articles related to the event!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8f3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ev_reactions = wnn.cd.extract_event_reactions(membership_df, core, list(membership_df.index))\n",
    "for k, v in ev_reactions.items():\n",
    "    print(k)\n",
    "    display(v) # NaN simply indicates not part of the community for this timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a318ca6",
   "metadata": {},
   "source": [
    "## 4. Visualisation\n",
    "\n",
    "A quick look at the page view time series for each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b79297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = sns.color_palette('colorblind', len(ev_reactions))\n",
    "\n",
    "# alter x values\n",
    "tsp = ts.copy()\n",
    "tsp.index = (tsp.index - tsp.index[len(tsp)//2]).days\n",
    "\n",
    "# plot page views for each community\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "for n, (k, v) in enumerate(ev_reactions.items()):\n",
    "    ax.plot(tsp[v.index], lw=1, alpha=0.25, c=palette[n])\n",
    "    ax.plot(tsp[v.index].mean(axis=1), lw=2, c=palette[n])\n",
    "\n",
    "# add legends\n",
    "legend_elements1 = [Line2D([0], [0], color='k', lw=0.25,\n",
    "                           label='Individual Article'),\n",
    "                    Line2D([0], [0], color='k', lw=2,\n",
    "                           label='Community Mean')]\n",
    "legend_elements2 = [Line2D([0], [0], color=palette[n], lw=1,\n",
    "                           label=k)\n",
    "                    for n, k in enumerate(ev_reactions.keys())] \n",
    "l1 = ax.legend(handles=legend_elements1, loc=2)\n",
    "l2 = ax.legend(handles=legend_elements2, title='Community', loc=4)\n",
    "ax.add_artist(l1)\n",
    "\n",
    "# tune other elements\n",
    "ax.set_ylabel('Page views (daily)')\n",
    "ax.set_xlabel('Days from event')\n",
    "ax.set_xlim(-30, 30)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Page views towards articles related to the Anchorage earthquake in 2018')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
